{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ec8bcd7d7b9d900",
   "metadata": {},
   "source": [
    "# Notebook - Raw Data Process\n",
    "No need to execute this notebook as the dataset is converted and produced in dataset folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8950f8d528b70191",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-01T14:00:53.792349300Z",
     "start_time": "2023-12-01T14:00:53.037961900Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from netCDF4 import Dataset\n",
    "from netCDF4 import num2date\n",
    "from haversine import inverse_haversine, Direction, Unit, haversine\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49784a7dd257e452",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Feature Processing & Engineering - Sequence Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89cf16046f31bb7",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### A. Surrogate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44cf430011acc2cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-20T02:13:37.097074300Z",
     "start_time": "2023-11-20T02:11:14.013308900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Import source file\n",
    "wild_fire_surrogate = Dataset('../raw_dataset/WILDFIRE_SURROGATE.nc')\n",
    "\n",
    "# 2. Get seq_dim for global time adjustments - Monthly Frequency\n",
    "surrogate_seq_dim = np.array(num2date(wild_fire_surrogate[\"time\"],wild_fire_surrogate[\"time\"].units))\n",
    "\n",
    "# === Input Features\n",
    "fuel_load_cwdc = np.array(wild_fire_surrogate[\"CWDC\"])\n",
    "fuel_load_deadcrootc = np.array(wild_fire_surrogate[\"DEADCROOTC\"])\n",
    "fuel_wetness = np.array(wild_fire_surrogate[\"SOILWATER_10CM\"])\n",
    "fuel_temperature = np.array(wild_fire_surrogate[\"TSOI_10CM\"])\n",
    "climate_wind = np.array(wild_fire_surrogate[\"WIND\"])\n",
    "climate_tbot = np.array(wild_fire_surrogate[\"TBOT\"])\n",
    "climate_rh2m = np.array(wild_fire_surrogate[\"RH2M\"])\n",
    "climate_rain = np.array(wild_fire_surrogate[\"RAIN\"])\n",
    "tree_coverage = np.array(wild_fire_surrogate[\"PCT_NAT_PFT\"])\n",
    "# === Output Variable\n",
    "burned_area = np.array(wild_fire_surrogate[\"FAREA_BURNED\"])\n",
    "\n",
    "# === size\n",
    "sorrogate_size = [wild_fire_surrogate[\"FAREA_BURNED\"][0].shape[0],wild_fire_surrogate[\"FAREA_BURNED\"][0].shape[1]]\n",
    "\n",
    "# print(\"#--> Start Time Frame: \",surrogate_seq_dim[0])\n",
    "# print(\"#--> End Time Frame: \",surrogate_seq_dim[-1])\n",
    "# print(\"#--> Time Frame Frequency: \",surrogate_seq_dim[1] - surrogate_seq_dim[0])\n",
    "# print(\"#--> Time Frame Length: \",len(surrogate_seq_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbad04a6b02001b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:46:35.907198900Z",
     "start_time": "2023-11-18T05:46:35.888163500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_transformation(feature, save_path, name):\n",
    "    feature = np.where(feature == feature.max(), 0, feature)\n",
    "    np.save(file = save_path + name + \".npy\",arr = feature)\n",
    "    print(\"Feature saved: \", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac77ddd203c30bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:23.859792500Z",
     "start_time": "2023-11-18T05:46:35.906196800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature saved:  fuel_load_cwdc\n",
      "Feature saved:  fuel_load_deadcrootc\n",
      "Feature saved:  fuel_wetness\n",
      "Feature saved:  fuel_temperature\n",
      "Feature saved:  climate_wind\n",
      "Feature saved:  climate_tbot\n",
      "Feature saved:  climate_rh2m\n",
      "Feature saved:  climate_rain\n",
      "Feature saved:  tree_coverage\n",
      "Feature saved:  percent_burned_area\n"
     ]
    }
   ],
   "source": [
    "# === define saving route\n",
    "save_path = \"../dataset/\"\n",
    "\n",
    "feature_transformation(fuel_load_cwdc, save_path, \"fuel_load_cwdc\")\n",
    "feature_transformation(fuel_load_deadcrootc, save_path, \"fuel_load_deadcrootc\")\n",
    "feature_transformation(fuel_wetness, save_path, \"fuel_wetness\")\n",
    "feature_transformation(fuel_temperature, save_path, \"fuel_temperature\")\n",
    "feature_transformation(climate_wind, save_path, \"climate_wind\")\n",
    "feature_transformation(climate_tbot, save_path, \"climate_tbot\")\n",
    "feature_transformation(climate_rh2m, save_path, \"climate_rh2m\")\n",
    "feature_transformation(climate_rain, save_path, \"climate_rain\")\n",
    "feature_transformation(tree_coverage, save_path, \"tree_coverage\")\n",
    "feature_transformation(burned_area, save_path, \"percent_burned_area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9028bbdfa65f7c59",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Burned Area Computation & Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943431b1d2bf0f60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:23.925967Z",
     "start_time": "2023-11-18T05:47:23.847265800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97 145 96\n",
      "506225092484712.06\n",
      "(96, 144)\n"
     ]
    }
   ],
   "source": [
    "# === compute the grid area\n",
    "\n",
    "# Mapping the (96,144) to standard lat and lon systems to find out the true lat and lon for each grid\n",
    "lat_angle = 90\n",
    "lon_ange = 180\n",
    "\n",
    "lat_list = np.arange(-lat_angle,lat_angle,lat_angle*2/97)\n",
    "lon_list = np.arange(-lon_ange,lon_ange,lon_ange*2/145)\n",
    "lat_list_for_lon_compute = np.arange(-lat_angle,lat_angle,lat_angle*2/96)\n",
    "print(len(lat_list),len(lon_list),len(lat_list_for_lon_compute)) # 97, 145\n",
    "\n",
    "# Create an x_distance list (x_distance for the grid will change with latitude change)\n",
    "x_distance = []\n",
    "for lon in range(len(lon_list) - 1):\n",
    "    temp_list = []\n",
    "    for lat in range(len(lat_list_for_lon_compute)):\n",
    "        temp_list.append(haversine((lat_list[lat],lon_list[lon]), (lat_list[lat],lon_list[lon+1]), unit=Unit.METERS)) # Haversine to compute the distance\n",
    "    x_distance.append(temp_list)\n",
    "# Transpose the dims\n",
    "x_distance = np.array(x_distance).transpose(1,0)\n",
    "# Compute y_distance (it is same for all grids)\n",
    "y_distance = haversine((lat_list[1],40), (lat_list[2],40), unit=Unit.METERS)\n",
    "# get area matrix for the world\n",
    "area = x_distance * y_distance\n",
    "# verify the outcome. The outcome equals to the surface area of the Earth (~= 5.1)\n",
    "print(area.sum())\n",
    "print(area.shape)\n",
    "# save to local disk\n",
    "np.save(file = save_path + \"grid_area.npy\",arr = area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d89f335c5256f80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:23.996021700Z",
     "start_time": "2023-11-18T05:47:23.923460500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Construct transformation_matrix\n",
    "transformation_matrix = []\n",
    "for i in range(1800):\n",
    "    transformation_matrix.append(area)\n",
    "transformation_matrix = np.array(transformation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a8821ee0b289611",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:26.191783800Z",
     "start_time": "2023-11-18T05:47:23.971098700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "burned_area = np.where(burned_area == burned_area.max(), 0, burned_area)\n",
    "# Compute the burned area\n",
    "burned_area = burned_area * 3600 * 30 * 24 * transformation_matrix\n",
    "# print the dimension for the matrix\n",
    "print(burned_area.shape)\n",
    "# save to local disk\n",
    "np.save(file = save_path + \"burned_area.npy\",arr = burned_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2f0459693fde15",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### B. Elemforc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fff25f3256d44e6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:32.260129700Z",
     "start_time": "2023-11-18T05:47:26.192784400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Import source file\n",
    "elmforc = Dataset('../raw_dataset/elmforc.ssp5_hdm_0.5x0.5_simyr1850-2100_c190109.nc')\n",
    "# 2. Get seq_dim for global time adjustments - Yearly Frequency\n",
    "elmforc_seq_dim = np.array(num2date(elmforc[\"time\"],elmforc[\"time\"].units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367bae92ee09aea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:38.040734600Z",
     "start_time": "2023-11-18T05:47:32.260129700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "# 1.0 Elmforc Conversion (Strategy: propagate annual value to each month)\n",
    "# Create an empty list to store index\n",
    "seq_index = []\n",
    "# Iterate time sequences to get index\n",
    "for timepoint in surrogate_seq_dim:\n",
    "    for i in range(0,len(elmforc_seq_dim)): # loop the elmforc seq to find out the time point greater than timepoint\n",
    "        if timepoint < elmforc_seq_dim[i]:\n",
    "            seq_index.append(i-1) # store the previous one's index in seq_index\n",
    "            break\n",
    "\n",
    "# create an empty list to store the feature\n",
    "population_density_pro = []\n",
    "# iterate the index list to get images and append in the list\n",
    "for seq in seq_index:\n",
    "    # A: Resizing - scaling to 96 * 144\n",
    "    sub_graph = cv2.resize(elmforc[\"hdm\"][seq], (sorrogate_size[1], sorrogate_size[0]))\n",
    "    # B: append the transformed matrix to the list\n",
    "    population_density_pro.append(sub_graph)\n",
    "# convert the list to array\n",
    "population_density = np.array(population_density_pro)\n",
    "# print the shape \n",
    "print(population_density.shape)  # (1, 1800, 96, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582f27d46a08f3e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:47:39.545705100Z",
     "start_time": "2023-11-18T05:47:38.040734600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to local disk\n",
    "np.save(file = save_path + \"human_density.npy\",arr = population_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c9386c4ef1f649",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### C. Clmforc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afc674fe2325cef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:48:10.451006700Z",
     "start_time": "2023-11-18T05:47:39.547929500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. Import source file\n",
    "clmforc = Dataset('../raw_dataset/clmforc.Li_2012_climo1995-2011.T62.lnfm_Total_c140423.nc')\n",
    "# 2. Get seq_dim for global time adjustments - Yearly Frequency\n",
    "clmforc_seq_dim = np.array(num2date(clmforc[\"time\"],clmforc[\"time\"].units))\n",
    "# 3. get the dim parameters for later resizing\n",
    "clmforc_size = [clmforc[\"lnfm\"][0].shape[0],clmforc[\"lnfm\"][0].shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f26bab78b956c28",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Clmforc - Lightning Frequency Feature Engineering - working needed\n",
    "- time adjustment\n",
    "- resolution adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a99ba13eeed16fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:48:17.310220700Z",
     "start_time": "2023-11-18T05:48:10.453006900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 96, 144)\n"
     ]
    }
   ],
   "source": [
    "# 2.0 Climatology Conversion (Strategy: split the dataset into 12 chunks and take the average for these matrix)\n",
    "# Create an empty list to store index\n",
    "seq_index = {}\n",
    "\n",
    "for i in range(0,len(clmforc_seq_dim)):\n",
    "    if i == 0:\n",
    "        seq_index[clmforc_seq_dim[i].month] = [i]\n",
    "    else:\n",
    "        if clmforc_seq_dim[i-1].month != clmforc_seq_dim[i].month:\n",
    "            seq_index[clmforc_seq_dim[i].month] = [i]\n",
    "        else:\n",
    "            seq_index[clmforc_seq_dim[i].month].append(i)\n",
    "\n",
    "# Create the list to store the month average lightning frequency matrix\n",
    "lightning_frequency_climatology_avg = []\n",
    "for mon in seq_index.keys():\n",
    "    temp_matrix = np.zeros((sorrogate_size[0], sorrogate_size[1]))\n",
    "    for i in seq_index[mon]:\n",
    "        # A: Resizing - scaling to 96 * 144\n",
    "        sub_graph = cv2.resize(clmforc[\"lnfm\"][i], (sorrogate_size[1], sorrogate_size[0]))\n",
    "        # B: Padding Zeros to 224 * 224\n",
    "\n",
    "        # C: append the transformed matrix to the list\n",
    "        temp_matrix += sub_graph\n",
    "    temp_matrix = temp_matrix / len(temp_matrix)\n",
    "    lightning_frequency_climatology_avg.append(temp_matrix)\n",
    "\n",
    "# Expand the list to the seq_index with corresponding months\n",
    "lightning_frequency_climatology_avg_pro = []\n",
    "for i in surrogate_seq_dim:\n",
    "    lightning_frequency_climatology_avg_pro.append(lightning_frequency_climatology_avg[i.month-1])\n",
    "lightning_frequency_climatology = np.array(lightning_frequency_climatology_avg_pro)\n",
    "# print the shape \n",
    "print(lightning_frequency_climatology.shape)  # (1, 1800, 96, 144)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "743a2f1927ae63ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-18T05:48:19.301742200Z",
     "start_time": "2023-11-18T05:48:17.295694500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to local disk\n",
    "np.save(file = save_path + \"light_frequency.npy\",arr = lightning_frequency_climatology)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28158080d23d4916",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Feature Processing & Engineering - Image Data Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc214e226ba7ca",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### A. Graph Conversion Function\n",
    "- Convert the 2 dim matrix to 3 dim matrix (lat, lon, RGB channels)\n",
    "- Magnifer the color change for compute vision learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4374ee656f5e3ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T12:31:24.908447600Z",
     "start_time": "2023-10-30T12:31:24.899442500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# === Function: single matrix conversion\n",
    "def Graph_Conversion(data):\n",
    "    # first gain the min value\n",
    "    min_color = np.min(data)\n",
    "    # set non-continental part to nan\n",
    "    data = np.where(data == 1e36, min_color-1000000, data)\n",
    "    # gain max value\n",
    "    max_color = np.max(data)\n",
    "    # set non-continental part to nan\n",
    "    data = np.where(data == min_color-1000000, -5000000000, data)\n",
    "    # compute color range\n",
    "    color_range =  max_color - min_color + 1\n",
    "    # copy the input data\n",
    "    target = np.ones((96,144,3))\n",
    "    \n",
    "    # Iterations for each data point\n",
    "    for loc, val in np.ndenumerate(data):\n",
    "        r = (val - min_color) / color_range\n",
    "        step = int(round(color_range/5))\n",
    "        idx = int(r * 5)\n",
    "        h = (idx + 1) * step + min_color\n",
    "        m = idx * step + min_color\n",
    "        local_r = (val - m) / (h-m)\n",
    "        if h == m:\n",
    "            local_r = 0\n",
    "        else:\n",
    "            None\n",
    "        if val < min_color:\n",
    "            target[loc] = np.array([0,0,0])\n",
    "        if val > max_color:\n",
    "            target[loc] = np.array([255, 255, 255])\n",
    "        if idx == 0:\n",
    "            target[loc] = np.array([0, int(local_r * 255), 255])\n",
    "        if idx == 1:\n",
    "            target[loc] = np.array([0, 255, int((1 - local_r) * 255)])\n",
    "        if idx == 2:\n",
    "            target[loc] = np.array([int(local_r * 255), 255, 0])\n",
    "        if idx == 3:\n",
    "            target[loc] = np.array([255, int((1 - local_r) * 255), 0])\n",
    "        if idx == 4:\n",
    "            target[loc] = np.array([255, 0, int(local_r * 255)])\n",
    "            \n",
    "    # return the converted matrix\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aefb6c6a53d9ab7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T12:31:24.929462200Z",
     "start_time": "2023-10-30T12:31:24.910953900Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# === Function: feature conversion (1800, 96, 144)\n",
    "def Seq_to_Img(feature):\n",
    "    feature_lst = []\n",
    "    # gain the time dim\n",
    "    time_dim = feature.shape[0]\n",
    "    for i in range(0, time_dim):\n",
    "        feature_lst.append(Graph_Conversion(feature[i]))\n",
    "    feature_lst = np.array(feature_lst)\n",
    "    print(\"-> Conversion Completed.\")\n",
    "    return feature_lst\n",
    "# === Function: feature conversion (1800, 17, 96, 144)\n",
    "def Seq_to_Img_Tree_Coverage(tc):\n",
    "    feature_lst = []\n",
    "    # gain the time dim\n",
    "    time_dim = tc.shape[0]\n",
    "    frame_dim = tc.shape[1]\n",
    "    for i in range(0, time_dim):\n",
    "        temp_lst = []\n",
    "        for j in range(0, frame_dim):\n",
    "            temp_lst.append(Graph_Conversion(tc[i][j]))\n",
    "        feature_lst.append(temp_lst)\n",
    "    feature_lst = np.array(feature_lst)\n",
    "    print(\"-> Conversion Completed.\")\n",
    "    return feature_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d22bdbda803ca1",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### B. Feature Transformation from Sequence to RGB Image Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7a3702dfcc266de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T12:56:56.065375800Z",
     "start_time": "2023-10-30T12:31:24.925960Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_27784\\2694456574.py:23: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  local_r = (val - m) / (h-m)\n",
      "C:\\Users\\A\\AppData\\Local\\Temp\\ipykernel_27784\\2694456574.py:23: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  local_r = (val - m) / (h-m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n",
      "-> Conversion Completed.\n"
     ]
    }
   ],
   "source": [
    "# === Call functions to perform conversions\n",
    "fuel_load_cwdc_img = Seq_to_Img(fuel_load_cwdc)\n",
    "fuel_load_deadcrootc_img = Seq_to_Img(fuel_load_deadcrootc)\n",
    "fuel_wetness_img = Seq_to_Img(fuel_wetness)\n",
    "fuel_temperature_img = Seq_to_Img(fuel_temperature)\n",
    "climate_wind_img = Seq_to_Img(climate_wind)\n",
    "climate_tbot_img = Seq_to_Img(climate_tbot)\n",
    "climate_rh2m_img = Seq_to_Img(climate_rh2m)\n",
    "climate_rain_img = Seq_to_Img(climate_rain)\n",
    "population_density_img = Seq_to_Img(population_density)\n",
    "lightning_frequency_climatology_img = Seq_to_Img(lightning_frequency_climatology)\n",
    "burned_area_img = Seq_to_Img(burned_area)\n",
    "tree_coverage_img = Seq_to_Img_Tree_Coverage(tree_coverage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2d1e9cfb703adf",
   "metadata": {},
   "source": [
    "### C. Save to Local Disk (Img Matrix Dataset) & Feature Engineering Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "520d63ae976def56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T12:56:56.083391400Z",
     "start_time": "2023-10-30T12:56:56.068377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Category</th>\n",
       "      <th>Feature Array Dimensions (time, lat, lon)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fuel_load_cwdc</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fuel_load_deadcrootc</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuel_wetness</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuel_temperature</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>climate_wind</td>\n",
       "      <td>Climate</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>climate_tbot</td>\n",
       "      <td>Climate</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>climate_rh2m</td>\n",
       "      <td>Climate</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>climate_rain</td>\n",
       "      <td>Climate</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>population_density</td>\n",
       "      <td>Population</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lightning_frequency</td>\n",
       "      <td>Light</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>burned_area</td>\n",
       "      <td>Output</td>\n",
       "      <td>(1800, 96, 144, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Feature    Category Feature Array Dimensions (time, lat, lon)\n",
       "1         fuel_load_cwdc        Fuel                        (1800, 96, 144, 3)\n",
       "2   fuel_load_deadcrootc        Fuel                        (1800, 96, 144, 3)\n",
       "3           fuel_wetness        Fuel                        (1800, 96, 144, 3)\n",
       "4       fuel_temperature        Fuel                        (1800, 96, 144, 3)\n",
       "5           climate_wind     Climate                        (1800, 96, 144, 3)\n",
       "6           climate_tbot     Climate                        (1800, 96, 144, 3)\n",
       "7           climate_rh2m     Climate                        (1800, 96, 144, 3)\n",
       "8           climate_rain     Climate                        (1800, 96, 144, 3)\n",
       "9     population_density  Population                        (1800, 96, 144, 3)\n",
       "10   lightning_frequency       Light                        (1800, 96, 144, 3)\n",
       "11           burned_area      Output                        (1800, 96, 144, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Summary for Feature Engineering\n",
    "feature_summary_panel = pd.DataFrame(columns = [\"Feature\",\"Category\",\"Feature Array Dimensions (time, lat, lon)\"])\n",
    "# === add to dataframe\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"fuel_load_cwdc\",\"Fuel\",fuel_load_cwdc_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"fuel_load_deadcrootc\",\"Fuel\",fuel_load_deadcrootc_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"fuel_wetness\",\"Fuel\",fuel_wetness_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"fuel_temperature\",\"Fuel\",fuel_temperature_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"climate_wind\",\"Climate\",climate_wind_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"climate_tbot\",\"Climate\",climate_tbot_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"climate_rh2m\",\"Climate\",climate_rh2m_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"climate_rain\",\"Climate\",climate_rain_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"tree_coverage\",\"Tree\",tree_coverage_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"population_density\",\"Population\",population_density_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"lightning_frequency\",\"Light\",lightning_frequency_climatology_img.shape]\n",
    "feature_summary_panel.loc[len(feature_summary_panel) + 1] = [\"burned_area\",\"Output\",burned_area_img.shape]\n",
    "# === show the result\n",
    "feature_summary_panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5304061c63212de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T13:00:45.583343900Z",
     "start_time": "2023-10-30T12:56:56.081902100Z"
    }
   },
   "outputs": [],
   "source": [
    "# === define saving route\n",
    "save_route = \"../dataset/\"\n",
    "\n",
    "# === save files to local disk\n",
    "np.save(file = save_route + \"fuel_load_cwdc_img.npy\",arr = fuel_load_cwdc_img)\n",
    "np.save(file = save_route + \"fuel_load_deadcrootc_img.npy\",arr = fuel_load_deadcrootc_img)\n",
    "np.save(file = save_route + \"fuel_wetness_img.npy\",arr = fuel_wetness_img)\n",
    "np.save(file = save_route + \"fuel_temperature_img.npy\",arr = fuel_temperature_img)\n",
    "np.save(file = save_route + \"climate_wind_img.npy\",arr = climate_wind_img)\n",
    "np.save(file = save_route + \"climate_tbot_img.npy\",arr = climate_tbot_img)\n",
    "np.save(file = save_route + \"climate_rh2m_img.npy\",arr = climate_rh2m_img)\n",
    "np.save(file = save_route + \"climate_rain_img.npy\",arr = climate_rain_img)\n",
    "np.save(file = save_route + \"tree_coverage_img.npy\",arr = tree_coverage_img)\n",
    "np.save(file = save_route + \"population_density_img.npy\",arr = population_density_img)\n",
    "np.save(file = save_route + \"lightning_frequency_climatology_img.npy\",arr = lightning_frequency_climatology_img)\n",
    "np.save(file = save_route + \"burned_area.npy\",arr = burned_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a4e9ae-94e8-4f18-bee7-f3f73160a823",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Regional Segmentation Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd0c500-838f-461b-8b1c-32e3a0a9e83c",
   "metadata": {},
   "source": [
    "### A. Import dataset and create dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b7e9c24-58e7-443f-88b5-57e3fab0b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_seg = np.array(Dataset('../raw_dataset/gfed_14regions.nc')[\"basic_14regions\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e683ba15-35c0-4de8-b7c3-9c411fac7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_dict = {\"BONA\":[],\"TENA\":[],\"CEAM\":[],\"NHSA\":[],\"SHSA\":[],\n",
    "               \"MIDE\":[],\"NHAF\":[],\"EURO\":[],\"SHAF\":[],\"BOAS\":[],\n",
    "               \"CEAS\":[],\"SEAS\":[],\"EQAS\":[],\"AUST\":[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f87818-341f-480b-939e-982d79b4814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lat in range(region_seg.shape[0]):\n",
    "    for lon in range(region_seg.shape[1]):\n",
    "        if region_seg[lat,lon] == 1:\n",
    "            region_dict[\"BONA\"] = region_dict[\"BONA\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 2:\n",
    "            region_dict[\"TENA\"] = region_dict[\"TENA\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 3:\n",
    "            region_dict[\"CEAM\"] = region_dict[\"CEAM\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 4:\n",
    "            region_dict[\"NHSA\"] = region_dict[\"NHSA\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 5:\n",
    "            region_dict[\"SHSA\"] = region_dict[\"SHSA\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 6:\n",
    "            region_dict[\"MIDE\"] = region_dict[\"MIDE\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 7:\n",
    "            region_dict[\"NHAF\"] = region_dict[\"NHAF\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 8:\n",
    "            region_dict[\"EURO\"] = region_dict[\"EURO\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 9:\n",
    "            region_dict[\"SHAF\"] = region_dict[\"SHAF\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 10:\n",
    "            region_dict[\"BOAS\"] = region_dict[\"BOAS\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 11:\n",
    "            region_dict[\"CEAS\"] = region_dict[\"CEAS\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 12:\n",
    "            region_dict[\"SEAS\"] = region_dict[\"SEAS\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 13:\n",
    "            region_dict[\"EQAS\"] = region_dict[\"EQAS\"]+[[lat,lon]]\n",
    "        elif region_seg[lat,lon] == 14:\n",
    "            region_dict[\"AUST\"] = region_dict[\"AUST\"]+[[lat,lon]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f44d80-5e25-481f-ba5b-e1526ca7dac1",
   "metadata": {},
   "source": [
    "### B. Save to local disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73e0bca7-18e3-4881-9a06-53f39bdede13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dataset/region_segmentation.json\",\"w\", encoding='utf-8') as f:\n",
    "    f.write(json.dumps(region_dict,ensure_ascii=False)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
